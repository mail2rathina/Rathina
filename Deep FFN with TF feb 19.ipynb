{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('D:\\Subscribers (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 51)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V42</th>\n",
       "      <th>V43</th>\n",
       "      <th>V44</th>\n",
       "      <th>V45</th>\n",
       "      <th>V46</th>\n",
       "      <th>V47</th>\n",
       "      <th>V48</th>\n",
       "      <th>V49</th>\n",
       "      <th>V50</th>\n",
       "      <th>Subscribers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.211875</td>\n",
       "      <td>743952.92</td>\n",
       "      <td>743952.92</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>743952.92</td>\n",
       "      <td>200000.000</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>-0.069396</td>\n",
       "      <td>943952.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.034232e+06</td>\n",
       "      <td>1966.57</td>\n",
       "      <td>1990.82</td>\n",
       "      <td>1752.89</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>1826.046667</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2557.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.241488</td>\n",
       "      <td>11295310.87</td>\n",
       "      <td>8034290.99</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>8034290.99</td>\n",
       "      <td>18000.000</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>0.167411</td>\n",
       "      <td>7508345.76</td>\n",
       "      <td>1160925.13</td>\n",
       "      <td>...</td>\n",
       "      <td>5.665658e+07</td>\n",
       "      <td>49957.65</td>\n",
       "      <td>11104.54</td>\n",
       "      <td>17711.99</td>\n",
       "      <td>38000.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26467.683330</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12807.07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.459032</td>\n",
       "      <td>20363.68</td>\n",
       "      <td>317922.94</td>\n",
       "      <td>1650000.0</td>\n",
       "      <td>317922.94</td>\n",
       "      <td>1650000.000</td>\n",
       "      <td>1650000.0</td>\n",
       "      <td>46.068404</td>\n",
       "      <td>1655168.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.654720e+04</td>\n",
       "      <td>453.96</td>\n",
       "      <td>9.64</td>\n",
       "      <td>58.83</td>\n",
       "      <td>45072.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>315.506667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>856120.91</td>\n",
       "      <td>856120.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>856120.91</td>\n",
       "      <td>45554.885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>856120.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>8.506973e+05</td>\n",
       "      <td>2045.09</td>\n",
       "      <td>2045.09</td>\n",
       "      <td>2011.19</td>\n",
       "      <td>45072.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2045.090000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2029.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.270783</td>\n",
       "      <td>194485.64</td>\n",
       "      <td>412330.33</td>\n",
       "      <td>835000.0</td>\n",
       "      <td>412330.33</td>\n",
       "      <td>835000.000</td>\n",
       "      <td>835000.0</td>\n",
       "      <td>-0.272225</td>\n",
       "      <td>2241.64</td>\n",
       "      <td>78625.00</td>\n",
       "      <td>...</td>\n",
       "      <td>5.572559e+04</td>\n",
       "      <td>70.01</td>\n",
       "      <td>100.60</td>\n",
       "      <td>89.59</td>\n",
       "      <td>31080.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.580000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1           V2          V3         V4          V5           V6  \\\n",
       "0 -0.211875    743952.92   743952.92   200000.0   743952.92   200000.000   \n",
       "1  0.241488  11295310.87  8034290.99    32000.0  8034290.99    18000.000   \n",
       "2  0.459032     20363.68   317922.94  1650000.0   317922.94  1650000.000   \n",
       "3  0.000000    856120.91   856120.91        0.0   856120.91    45554.885   \n",
       "4  8.270783    194485.64   412330.33   835000.0   412330.33   835000.000   \n",
       "\n",
       "          V7         V8          V9         V10  ...           V42       V43  \\\n",
       "0   200000.0  -0.069396   943952.92        0.00  ...  1.034232e+06   1966.57   \n",
       "1    14000.0   0.167411  7508345.76  1160925.13  ...  5.665658e+07  49957.65   \n",
       "2  1650000.0  46.068404  1655168.31        0.00  ...  2.654720e+04    453.96   \n",
       "3        0.0   0.000000   856120.91        0.00  ...  8.506973e+05   2045.09   \n",
       "4   835000.0  -0.272225     2241.64    78625.00  ...  5.572559e+04     70.01   \n",
       "\n",
       "        V44       V45       V46    V47           V48   V49       V50  \\\n",
       "0   1990.82   1752.89  100000.0  147.0   1826.046667  28.0   2557.22   \n",
       "1  11104.54  17711.99   38000.0   19.0  26467.683330  19.0  12807.07   \n",
       "2      9.64     58.83   45072.0    0.0    315.506667   0.0     32.12   \n",
       "3   2045.09   2011.19   45072.0   30.0   2045.090000  19.0   2029.79   \n",
       "4    100.60     89.59   31080.0    0.0    294.580000   0.0     26.95   \n",
       "\n",
       "   Subscribers  \n",
       "0            0  \n",
       "1            0  \n",
       "2            1  \n",
       "3            0  \n",
       "4            0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.get_dummies(data['Subscribers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  1\n",
       "0       1  0\n",
       "1       1  0\n",
       "2       0  1\n",
       "3       1  0\n",
       "4       1  0\n",
       "...    .. ..\n",
       "299995  1  0\n",
       "299996  1  0\n",
       "299997  1  0\n",
       "299998  1  0\n",
       "299999  0  1\n",
       "\n",
       "[300000 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop(['Subscribers'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,\n",
    "                                               random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.reset_index(drop=True,inplace=True)\n",
    "y_train.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "st=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=pd.DataFrame(st.transform(x_train))\n",
    "x_test=pd.DataFrame(st.transform(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240000, 50)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.random.normal(shape=(50, 2), dtype=tf.float64))\n",
    "biases  = tf.Variable(tf.random.normal(shape=(2,), dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(x):\n",
    "    lr = tf.add(tf.matmul(x, weights), biases)#wx+b\n",
    "    return lr\n",
    "\n",
    "\n",
    "def cross_entropy(y_true, y_pred):#softmax for cat var coz we converted to cat else binary\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.cast(tf.argmax(y_true, axis=1), dtype=tf.int32)\n",
    "    preds = tf.cast(tf.argmax(y_pred, axis=1), dtype=tf.int32)\n",
    "    preds = tf.equal(y_true, preds)\n",
    "    return tf.reduce_mean(tf.cast(preds, dtype=tf.float32))\n",
    "\n",
    "def roc_auc(y_true,x):\n",
    "    y_true = tf.cast(tf.argmax(y_true, axis=1), dtype=tf.int32).numpy()\n",
    "    y_pred=tf.nn.softmax(logistic_regression(x))[:,1]\n",
    "    return(roc_auc_score(y_true,y_pred))\n",
    "\n",
    "def grad(x, y):#to cal loss\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = logistic_regression(x)\n",
    "        loss_val = cross_entropy(y, y_pred)\n",
    "    return tape.gradient(loss_val, [weights, biases])#return 2 var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=2000 #iterartion in alg to see data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=tf.cast(tf.argmax(y_test.values,axis=1),dtype=tf.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=tf.cast(tf.argmax(logistic_regression(x_test.values),axis=1),dtype=tf.int32)#cont 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.6953833>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(tf.cast(tf.equal(y_true,preds),dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epouch=0 0.69565 0.5116819354637383\n",
      "epouch=50 0.70915 0.519238756990498\n",
      "epouch=100 0.72255 0.5283581425154086\n",
      "epouch=150 0.73441666 0.5371032972363021\n",
      "epouch=200 0.7462 0.5450988317640568\n",
      "epouch=250 0.75778335 0.5529644445509727\n",
      "epouch=300 0.7683167 0.5593542260366638\n",
      "epouch=350 0.7781 0.5654668653686361\n",
      "epouch=400 0.78818333 0.5726825109347184\n",
      "epouch=450 0.7968 0.5784915706857383\n",
      "epouch=500 0.8048 0.5850497211584579\n",
      "epouch=550 0.8096833 0.5893213365212698\n",
      "epouch=600 0.81455 0.594437167718085\n",
      "epouch=650 0.8179 0.599297559228883\n",
      "epouch=700 0.82011664 0.6053741612889105\n",
      "epouch=750 0.82145 0.6084325270396375\n",
      "epouch=800 0.8224667 0.6127484577942764\n",
      "epouch=850 0.82283336 0.6157427868073911\n",
      "epouch=900 0.8234 0.6190446468995611\n",
      "epouch=950 0.8236833 0.6230005683358152\n",
      "epouch=1000 0.8237 0.6263587966216893\n",
      "epouch=1050 0.82375 0.6293201694568067\n",
      "epouch=1100 0.82376665 0.6328747671722611\n",
      "epouch=1150 0.8239833 0.6354280894594005\n",
      "epouch=1200 0.82441664 0.6362800676182309\n",
      "epouch=1250 0.8243167 0.6399291867313223\n",
      "epouch=1300 0.8244 0.6414457980790994\n",
      "epouch=1350 0.8242 0.6439637297918824\n",
      "epouch=1400 0.8243 0.6450693247701144\n",
      "epouch=1450 0.82425 0.6469562564529575\n",
      "epouch=1500 0.82453334 0.6479165144517686\n",
      "epouch=1550 0.82458335 0.64971158674744\n",
      "epouch=1600 0.82458335 0.6517099702144767\n",
      "epouch=1650 0.82488334 0.6523199476883781\n",
      "epouch=1700 0.82486665 0.6527799157439399\n",
      "epouch=1750 0.825 0.6533851289517726\n",
      "epouch=1800 0.8250833 0.6542639870665484\n",
      "epouch=1850 0.82498336 0.6567875690797089\n",
      "epouch=1900 0.8255 0.653916280632492\n",
      "epouch=1950 0.82561666 0.6553331911406197\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.01\n",
    "for epoch in range(epochs):\n",
    "    rand_ind=np.random.choice(range(x_train.shape[0]),100)# selection of batch,100 random sample\n",
    "    outputs=y_train.iloc[rand_ind,:].values\n",
    "    inputs=x_train.iloc[rand_ind,:].values\n",
    "    \n",
    "    dw,db=grad(inputs,tf.cast(outputs,'float32'))#cal grad dw=dl/dw\n",
    "    \n",
    "    weights.assign_sub(learning_rate*dw)\n",
    "    biases.assign_sub(learning_rate*db)\n",
    "    \n",
    "    if epoch%50==0:#print the val\n",
    "        print('epouch={}'.format(epoch),accuracy(y_test.values,logistic_regression(x_test.values)).numpy(),roc_auc(y_test.values,x_test.values))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classfier with a 1hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden layer weights(50,20)\n",
    "weights_h = tf.Variable(tf.random.truncated_normal(shape=(50, 20), dtype=tf.float64))\n",
    "biases_h  = tf.Variable(tf.random.truncated_normal(shape=(20,), dtype=tf.float64))\n",
    "#ooupt layer\n",
    "weights_o = tf.Variable(tf.random.truncated_normal(shape=(20, 2), dtype=tf.float64))\n",
    "biases_o  = tf.Variable(tf.random.truncated_normal(shape=(2,), dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(x):\n",
    "    h_o = tf.add(tf.matmul(x, weights_h), biases_h)#ho-output of hidden layer\n",
    "    h_o=tf.nn.relu(h_o)#activation func relu\n",
    "    lr=tf.add(tf.matmul(h_o, weights_o), biases_o)#ho is i/p wrt weights to o/p layer\n",
    "    return lr\n",
    "\n",
    "\n",
    "def cross_entropy(y_true, y_pred):\n",
    "\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.cast(tf.argmax(y_true, axis=1), dtype=tf.int32)\n",
    "    preds = tf.cast(tf.argmax(y_pred, axis=1), dtype=tf.int32)\n",
    "    preds = tf.equal(y_true, preds)\n",
    "    return tf.reduce_mean(tf.cast(preds, dtype=tf.float32))\n",
    "\n",
    "def roc_auc(y_true,x):\n",
    "    y_true = tf.cast(tf.argmax(y_true, axis=1), dtype=tf.int32).numpy()\n",
    "    y_pred=tf.nn.softmax(logistic_regression(x))[:,1]\n",
    "    return(roc_auc_score(y_true,y_pred))\n",
    "\n",
    "def grad(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = logistic_regression(x)\n",
    "        loss_val = cross_entropy(y, y_pred)\n",
    "    return tape.gradient(loss_val, [weights_h, biases_h,weights_o, biases_o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24645 0.5380973202735381\n",
      "0.7632 0.5750490050239142\n",
      "0.7894167 0.5832840970482777\n",
      "0.79466665 0.5874335920704606\n",
      "0.7965 0.5956745141419634\n",
      "0.7936 0.5975887517024265\n",
      "0.79768336 0.6012882897821649\n",
      "0.78891665 0.6054790435243419\n",
      "0.79975 0.607536433750318\n",
      "0.80836666 0.6113583881667111\n",
      "0.80785 0.6133241612728897\n",
      "0.8085 0.6124675761264071\n",
      "0.8124667 0.6141138903928788\n",
      "0.81015 0.6151812256867595\n",
      "0.81591666 0.6180763296030123\n",
      "0.8150333 0.6127972238722238\n",
      "0.81905 0.6113101173692429\n",
      "0.8197 0.6133386308872036\n",
      "0.8189333 0.6189028247508385\n",
      "0.82128334 0.6217868595879801\n",
      "0.82028335 0.6244782566946154\n",
      "0.82198334 0.624085629200296\n",
      "0.82123333 0.6262820408469202\n",
      "0.8237333 0.630263357374567\n",
      "0.82425 0.6316249801233295\n",
      "0.82406664 0.6329860519091924\n",
      "0.8228 0.6329480882208672\n",
      "0.8249 0.633974153072139\n",
      "0.82411665 0.6388804737880807\n",
      "0.82568336 0.6384328652761526\n",
      "0.8255 0.6340130213555798\n",
      "0.82625 0.6352355122957375\n",
      "0.8257833 0.6370337770501977\n",
      "0.82625 0.6396322255433606\n",
      "0.82633334 0.6405099270268004\n",
      "0.82448334 0.6409693714722304\n",
      "0.8271833 0.639251092072942\n",
      "0.8269333 0.6385646929187958\n",
      "0.82706666 0.6369928494940743\n",
      "0.8277 0.6378434004245416\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.01\n",
    "for epoch in range(epochs):\n",
    "    rand_ind=np.random.choice(range(x_train.shape[0]),100)\n",
    "    outputs=y_train.iloc[rand_ind,:].values\n",
    "    inputs=x_train.iloc[rand_ind,:].values\n",
    "    \n",
    "    dw_h,db_h,dw_o,db_o=grad(inputs,tf.cast(outputs,'float32')) #dh/dw,dh/db\n",
    "    \n",
    "    weights_h.assign_sub(learning_rate*dw_h)#updateding the weights\n",
    "    biases_h.assign_sub(learning_rate*db_h)\n",
    "    weights_o.assign_sub(learning_rate*dw_o)\n",
    "    biases_o.assign_sub(learning_rate*db_o)\n",
    "    \n",
    "    if epoch%50==0:\n",
    "        print(accuracy(y_test.values,logistic_regression(x_test.values)).numpy(),roc_auc(y_test.values,x_test.values))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifier with 2 hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weights_h1 = tf.Variable(tf.random.truncated_normal(shape=(50, 30), dtype=tf.float64))\n",
    "biases_h1  = tf.Variable(tf.random.truncated_normal(shape=(30,), dtype=tf.float64))\n",
    "\n",
    "weights_h2 = tf.Variable(tf.random.truncated_normal(shape=(30, 10), dtype=tf.float64))\n",
    "biases_h2  = tf.Variable(tf.random.truncated_normal(shape=(10,), dtype=tf.float64))\n",
    "\n",
    "weights_o = tf.Variable(tf.random.truncated_normal(shape=(10, 2), dtype=tf.float64))\n",
    "biases_o  = tf.Variable(tf.random.truncated_normal(shape=(2,), dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6103 0.5712062556655887\n",
      "0.73765 0.572267332060002\n",
      "0.65056664 0.5749276144160623\n",
      "0.68745 0.5704915630035181\n",
      "0.7111833 0.5652227692662954\n",
      "0.7266 0.5764507171618355\n",
      "0.73866665 0.5698978262356639\n",
      "0.7375 0.5655830833726673\n",
      "0.73035 0.571623401008953\n",
      "0.76705 0.5716266257049326\n",
      "0.7435167 0.5895714805160098\n",
      "0.7861 0.5664943310723873\n",
      "0.77743334 0.587868504013577\n",
      "0.74803334 0.602347744548185\n",
      "0.7996167 0.5897901864113808\n",
      "0.8010167 0.5807453606247166\n",
      "0.81525 0.5816843889679596\n",
      "0.8168 0.5951303298441387\n",
      "0.81736666 0.6028942001026447\n",
      "0.81703335 0.6063052153233739\n",
      "0.82233334 0.5842064851396827\n",
      "0.8254 0.5906774457334952\n",
      "0.8258833 0.5920278460322689\n",
      "0.82545 0.6101107082578062\n",
      "0.8258167 0.6120629505357466\n",
      "0.8258 0.6143219111247764\n",
      "0.8265833 0.5998559210525338\n",
      "0.8265667 0.6212295430308238\n",
      "0.8267 0.6133274377437519\n",
      "0.8268333 0.6138695295548182\n",
      "0.82701665 0.6052127301361288\n",
      "0.8171833 0.6209233834977108\n",
      "0.82698333 0.6190628677506402\n",
      "0.8234 0.6287484633898712\n",
      "0.82755 0.6251121053199735\n",
      "0.8271833 0.6258533516585417\n",
      "0.8268667 0.628810910736281\n",
      "0.828 0.6223671016723256\n",
      "0.82781667 0.6265737932863319\n",
      "0.82778335 0.6234627402429765\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.01\n",
    "for epoch in range(epochs):\n",
    "    rand_ind=np.random.choice(range(x_train.shape[0]),100)\n",
    "    outputs=y_train.iloc[rand_ind,:].values\n",
    "    inputs=x_train.iloc[rand_ind,:].values\n",
    "    \n",
    "    dw_h1,db_h1,dw_h2,db_h2,dw_o,db_o=grad(inputs,tf.cast(outputs,'float32'))\n",
    "    \n",
    "    weights_h1.assign_sub(learning_rate*dw_h1)\n",
    "    biases_h1.assign_sub(learning_rate*db_h1)\n",
    "    weights_h2.assign_sub(learning_rate*dw_h2)\n",
    "    biases_h2.assign_sub(learning_rate*db_h2)\n",
    "    weights_o.assign_sub(learning_rate*dw_o)\n",
    "    biases_o.assign_sub(learning_rate*db_o)\n",
    "    \n",
    "    if epoch%50==0:\n",
    "        print(accuracy(y_test.values,logistic_regression(x_test.values)).numpy(),roc_auc(y_test.values,x_test.values))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
